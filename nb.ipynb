{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "from model import DCGAN\n",
    "from utils import pp, visualize, to_json, show_all_variables\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", 250, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.0002, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_integer(\"train_size\", np.inf, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 128, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", 160, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", None, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", 64, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", None, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"data_dir\", \"data\", \"Directory with image datasets [data]\")\n",
    "flags.DEFINE_string(\"dataset\", \"customData3\", \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_string(\"input_fname_labels\", \"labels.txt\", \"The mapping between images and identities [*]\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", \"*.png\", \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Directory name to save the checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"sample_dir\", \"samples\", \"Directory name to save the image samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", True, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", False, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", False, \"True for visualizing, False for nothing [False]\")\n",
    "flags.DEFINE_integer(\"generate_test_images\", 100, \"Number of images to generate during test. [100]\")\n",
    "flags.DEFINE_boolean(\"conditional\", True, \"Model and train conditional GAN\")\n",
    "flags.DEFINE_integer(\"loss_type\", 0, \"Loss type [0=cross entropy] 1=logloss 2=wasserstein\")\n",
    "flags.DEFINE_boolean(\"generate\", False, \"Generate 100 sample images for testing. Defaults to [False]\")\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    pp.pprint(flags.FLAGS.__flags)\n",
    "\n",
    "    if FLAGS.input_width is None:\n",
    "        FLAGS.input_width = FLAGS.input_height\n",
    "    if FLAGS.output_width is None:\n",
    "        FLAGS.output_width = FLAGS.output_height\n",
    "\n",
    "    if not os.path.exists(FLAGS.checkpoint_dir):\n",
    "        os.makedirs(FLAGS.checkpoint_dir)\n",
    "    if not os.path.exists(FLAGS.sample_dir):\n",
    "        os.makedirs(FLAGS.sample_dir)\n",
    "\n",
    "    # y_dim is inferred from the dataset name or the labels file\n",
    "    if FLAGS.conditional and FLAGS.dataset != 'mnist':\n",
    "        labels_fname = os.path.join(FLAGS.data_dir, FLAGS.dataset, FLAGS.input_fname_labels)\n",
    "        print(labels_fname)\n",
    "        if not os.path.exists(labels_fname):\n",
    "            raise Exception(\"[!] conditional requires image<->identity labels\")\n",
    "\n",
    "    #gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "    run_config = tf.ConfigProto()\n",
    "    run_config.gpu_options.allow_growth=True\n",
    "\n",
    "    with tf.Session(config=run_config) as sess:\n",
    "        dcgan = DCGAN(\n",
    "            sess,\n",
    "            input_width=FLAGS.input_width,\n",
    "            input_height=FLAGS.input_height,\n",
    "            output_width=FLAGS.output_width,\n",
    "            output_height=FLAGS.output_height,\n",
    "            batch_size=FLAGS.batch_size,\n",
    "            sample_num=FLAGS.batch_size,\n",
    "            z_dim=FLAGS.generate_test_images,\n",
    "            data_dir=FLAGS.data_dir,\n",
    "            dataset_name=FLAGS.dataset,\n",
    "            input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "            crop=FLAGS.crop,\n",
    "            checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "            sample_dir=FLAGS.sample_dir,\n",
    "            conditional = FLAGS.conditional,\n",
    "            loss_type=FLAGS.loss_type)\n",
    "\n",
    "        show_all_variables()\n",
    "\n",
    "        if FLAGS.train:\n",
    "            dcgan.train(FLAGS)\n",
    "        else:\n",
    "            if not dcgan.load(FLAGS.checkpoint_dir)[0]:\n",
    "                raise Exception(\"[!] Train a model first, then run test mode\")\n",
    "\n",
    "            if FLAGS.generate:\n",
    "                generate_samples(sess, dcgan, FLAGS)\n",
    "            exit()\n",
    "        # to_json(\"./web/js/layers.js\", [dcgan.h0_w, dcgan.h0_b, dcgan.g_bn0],\n",
    "        #                 [dcgan.h1_w, dcgan.h1_b, dcgan.g_bn1],\n",
    "        #                 [dcgan.h2_w, dcgan.h2_b, dcgan.g_bn2],\n",
    "        #                 [dcgan.h3_w, dcgan.h3_b, dcgan.g_bn3],\n",
    "        #                 [dcgan.h4_w, dcgan.h4_b, None])\n",
    "\n",
    "        # Below is codes for visualization\n",
    "        OPTION = 1\n",
    "        visualize(sess, dcgan, FLAGS, OPTION)\n",
    "     \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
